{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U5IgSqnfn-ZZ"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "D_l2wVSIn-Za"
      },
      "outputs": [],
      "source": [
        "train = gzip.open('train-images-idx3-ubyte.gz', 'rb')\n",
        "train_label = gzip.open('train-labels-idx1-ubyte.gz', 'rb')\n",
        "test = gzip.open('t10k-images-idx3-ubyte.gz', 'rb')\n",
        "test_label = gzip.open('t10k-labels-idx1-ubyte.gz', 'rb')\n",
        "\n",
        "train.read(16)\n",
        "train_label.read(8)\n",
        "test.read(16)\n",
        "test_label.read(8)\n",
        "\n",
        "train_image_data = np.frombuffer(train.read(), dtype=np.uint8).reshape(-1, 28, 28)\n",
        "train_label_data = np.frombuffer(train_label.read(), dtype=np.uint8)\n",
        "\n",
        "test_image_data = np.frombuffer(test.read(), dtype=np.uint8).reshape(-1, 28, 28)\n",
        "test_label_data = np.frombuffer(test_label.read(), dtype=np.uint8)\n",
        "\n",
        "# Ensure train_image_data and train_label_data have compatible shapes\n",
        "train_image_data = train_image_data[:len(train_label_data)] # This will keep the first 12000 entries from the image data, or\n",
        "# train_label_data = train_label_data[:len(train_image_data)] # will keep the first 48000 labels, based on your desired approach.\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_image_data, train_label_data, test_size=0.2, random_state=42 # Added random_state for reproducibility.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g-Zmz8BZn-Zb"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToPILImage(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "train_images = torch.tensor(train_images, dtype=torch.float32)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long)  # Labels should be long tensors\n",
        "val_images = torch.tensor(val_images, dtype=torch.float32)\n",
        "val_labels = torch.tensor(val_labels, dtype=torch.long)\n",
        "test_image_data = torch.tensor(test_image_data, dtype=torch.float32)\n",
        "test_label_data = torch.tensor(test_label_data, dtype=torch.long)\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(train_images, train_labels)\n",
        "val_dataset = TensorDataset(val_images, val_labels)\n",
        "test_dataset = TensorDataset(test_image_data, test_label_data)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CPItzuEIn-Zc"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 64 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNN()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "6tBS3TdrpB1X"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images = images.unsqueeze(1).float()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.unsqueeze(1).float()\n",
        "            output = model(images)\n",
        "            val_loss += criterion(output, labels).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print('Epoch: {} \\tValidation Loss: {:.6f} \\tValidation Accuracy: {:.0f}%'.format(epoch, val_loss, 100. * correct / len(val_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0DDChxPrOI8",
        "outputId": "67b1842d-c6e8-4b5b-a3e2-c2ff4482188f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \tValidation Loss: 0.006219 \tValidation Accuracy: 86%\n",
            "Epoch: 1 \tValidation Loss: 0.005054 \tValidation Accuracy: 88%\n",
            "Epoch: 2 \tValidation Loss: 0.005176 \tValidation Accuracy: 88%\n",
            "Epoch: 3 \tValidation Loss: 0.005487 \tValidation Accuracy: 88%\n",
            "Epoch: 4 \tValidation Loss: 0.004785 \tValidation Accuracy: 89%\n",
            "Epoch: 5 \tValidation Loss: 0.004794 \tValidation Accuracy: 90%\n",
            "Epoch: 6 \tValidation Loss: 0.005137 \tValidation Accuracy: 89%\n",
            "Epoch: 7 \tValidation Loss: 0.005217 \tValidation Accuracy: 89%\n",
            "Epoch: 8 \tValidation Loss: 0.005519 \tValidation Accuracy: 89%\n",
            "Epoch: 9 \tValidation Loss: 0.005380 \tValidation Accuracy: 90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1MtMGg_n-Zc"
      },
      "source": [
        "Sources:\n",
        "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}