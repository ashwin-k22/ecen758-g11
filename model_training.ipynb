{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U5IgSqnfn-ZZ"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D_l2wVSIn-Za"
   },
   "outputs": [],
   "source": [
    "train = gzip.open('train-images-idx3-ubyte.gz', 'rb')\n",
    "train_label = gzip.open('train-labels-idx1-ubyte.gz', 'rb')\n",
    "test = gzip.open('t10k-images-idx3-ubyte.gz', 'rb')\n",
    "test_label = gzip.open('t10k-labels-idx1-ubyte.gz', 'rb')\n",
    "\n",
    "train.read(16)\n",
    "train_label.read(8)\n",
    "test.read(16)\n",
    "test_label.read(8)\n",
    "\n",
    "train_image_data = np.frombuffer(train.read(), dtype=np.uint8).reshape(-1, 28, 28)\n",
    "train_label_data = np.frombuffer(train_label.read(), dtype=np.uint8)\n",
    "\n",
    "test_image_data = np.frombuffer(test.read(), dtype=np.uint8).reshape(-1, 28, 28)\n",
    "test_label_data = np.frombuffer(test_label.read(), dtype=np.uint8)\n",
    "\n",
    "# Ensure train_image_data and train_label_data have compatible shapes\n",
    "train_image_data = train_image_data[:len(train_label_data)] # This will keep the first 12000 entries from the image data, or\n",
    "# train_label_data = train_label_data[:len(train_image_data)] # will keep the first 48000 labels, based on your desired approach.\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_image_data, train_label_data, test_size=0.2, random_state=42 # Added random_state for reproducibility.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g-Zmz8BZn-Zb"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "transform_val_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images.numpy().astype(np.uint8)\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.fromarray(self.images[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_images = torch.tensor(train_images, dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)  # Labels should be long tensors\n",
    "val_images = torch.tensor(val_images, dtype=torch.float32)\n",
    "val_labels = torch.tensor(val_labels, dtype=torch.long)\n",
    "test_image_data = torch.tensor(test_image_data, dtype=torch.float32)\n",
    "test_label_data = torch.tensor(test_label_data, dtype=torch.long)\n",
    "\n",
    "# Create custom datasets with transforms\n",
    "train_dataset = CustomDataset(train_images, train_labels, transform=transform_train)\n",
    "val_dataset = CustomDataset(val_images, val_labels, transform=transform_val_test)\n",
    "test_dataset = CustomDataset(test_image_data, test_label_data, transform=transform_val_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CPItzuEIn-Zc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2304, out_features=512, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(-1, 64 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6tBS3TdrpB1X"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0DDChxPrOI8",
    "outputId": "8964885a-d12d-4c05-b03d-b79cfc9365c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tValidation Loss: 0.006354 \tValidation Accuracy: 85.47%\n",
      "Epoch: 2 \tValidation Loss: 0.005423 \tValidation Accuracy: 87.35%\n",
      "Epoch: 3 \tValidation Loss: 0.004820 \tValidation Accuracy: 88.59%\n",
      "Epoch: 4 \tValidation Loss: 0.004699 \tValidation Accuracy: 89.02%\n",
      "Epoch: 5 \tValidation Loss: 0.004374 \tValidation Accuracy: 89.64%\n",
      "Epoch: 6 \tValidation Loss: 0.004361 \tValidation Accuracy: 89.64%\n",
      "Epoch: 7 \tValidation Loss: 0.004089 \tValidation Accuracy: 90.46%\n",
      "Epoch: 8 \tValidation Loss: 0.004095 \tValidation Accuracy: 90.58%\n",
      "Epoch: 9 \tValidation Loss: 0.004132 \tValidation Accuracy: 90.14%\n",
      "Epoch: 10 \tValidation Loss: 0.003944 \tValidation Accuracy: 90.92%\n",
      "Epoch: 11 \tValidation Loss: 0.003846 \tValidation Accuracy: 91.08%\n",
      "Epoch: 12 \tValidation Loss: 0.003845 \tValidation Accuracy: 91.12%\n",
      "Epoch: 13 \tValidation Loss: 0.003664 \tValidation Accuracy: 91.34%\n",
      "Epoch: 14 \tValidation Loss: 0.003644 \tValidation Accuracy: 91.55%\n",
      "Epoch: 15 \tValidation Loss: 0.003629 \tValidation Accuracy: 91.52%\n",
      "Epoch: 16 \tValidation Loss: 0.003634 \tValidation Accuracy: 91.48%\n",
      "Epoch: 17 \tValidation Loss: 0.003486 \tValidation Accuracy: 91.91%\n",
      "Epoch: 18 \tValidation Loss: 0.003498 \tValidation Accuracy: 91.87%\n",
      "Epoch: 19 \tValidation Loss: 0.003632 \tValidation Accuracy: 91.59%\n",
      "Epoch: 20 \tValidation Loss: 0.003420 \tValidation Accuracy: 92.07%\n",
      "Epoch: 21 \tValidation Loss: 0.003443 \tValidation Accuracy: 91.86%\n",
      "Epoch: 22 \tValidation Loss: 0.003396 \tValidation Accuracy: 92.03%\n",
      "Epoch: 23 \tValidation Loss: 0.003467 \tValidation Accuracy: 92.08%\n",
      "Epoch: 24 \tValidation Loss: 0.003522 \tValidation Accuracy: 91.73%\n",
      "Epoch: 25 \tValidation Loss: 0.003497 \tValidation Accuracy: 92.00%\n",
      "Epoch: 26 \tValidation Loss: 0.003308 \tValidation Accuracy: 92.28%\n",
      "Epoch: 27 \tValidation Loss: 0.003323 \tValidation Accuracy: 92.30%\n",
      "Epoch: 28 \tValidation Loss: 0.003360 \tValidation Accuracy: 92.09%\n",
      "Epoch: 29 \tValidation Loss: 0.003341 \tValidation Accuracy: 92.47%\n",
      "Epoch: 30 \tValidation Loss: 0.003373 \tValidation Accuracy: 92.23%\n",
      "Epoch: 31 \tValidation Loss: 0.003295 \tValidation Accuracy: 92.51%\n",
      "Epoch: 32 \tValidation Loss: 0.003269 \tValidation Accuracy: 92.26%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(32):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.float()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.float()\n",
    "            output = model(images)\n",
    "            val_loss += criterion(output, labels).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f} \\tValidation Accuracy: {:.2f}%'.format(epoch + 1, val_loss, 100. * correct / len(val_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1MtMGg_n-Zc"
   },
   "source": [
    "Sources:\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "https://www.quora.com/How-do-I-choose-the-number-of-epochs-to-have-a-good-accuracy-of-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
